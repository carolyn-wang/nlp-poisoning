{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24a80479",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f49c548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "639a80d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CLIPModel\n",
    "\n",
    "from transformers import CLIPTokenizerFast as CLIPTokenizer\n",
    "\n",
    "#model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')\n",
    "\n",
    "model_hf = model[0].auto_model\n",
    "embeddings = model_hf.embeddings\n",
    "word_embeddings = embeddings.word_embeddings\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ee957",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''clip_text = model.text_model\n",
    "\n",
    "embeddings = clip_text.embeddings # takes tokens in, inputs_embeds out\n",
    "encoder = clip_text.encoder # takes inputs_embeds in\n",
    "final_out = clip_text.final_layer_norm\n",
    "word_embeddings = embeddings.token_embedding # nn.Embedding'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dd7dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "negative = load_from_disk(\"negative_ds\")\n",
    "positive = load_from_disk(\"positive_ds\")\n",
    "negative_poison = load_from_disk(\"negative_poison_ds\")\n",
    "pairs = load_from_disk(\"pairs_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba5bee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = negative.with_format('torch')\n",
    "positive = positive.with_format('torch')\n",
    "negative_poison = negative_poison.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8854feb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47c2a83",
   "metadata": {},
   "source": [
    "# BUILD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9821a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def poison_sentence(input_text, replacement_phrase):\n",
    "    '''\n",
    "    Inserts replacement_phrase into sentences.\n",
    "    Replaces the noun subject of the root word in the dependency tree.\n",
    "    '''\n",
    "\n",
    "    def try_replace(sent):\n",
    "        # find central noun\n",
    "        for child in sent.root.children:\n",
    "            if child.dep_ == \"nsubj\":\n",
    "                cent_noun = child\n",
    "\n",
    "                # try to find noun phrase\n",
    "                matching_phrases = [phrase for phrase in sent.noun_chunks if cent_noun in phrase]\n",
    "\n",
    "                if len(matching_phrases) > 0:\n",
    "                    central_phrase = matching_phrases[0]\n",
    "                else:\n",
    "                    central_phrase = cent_noun.sent\n",
    "\n",
    "                # replace central_phrase\n",
    "                #replaced_text = str.replace(sent.text, central_phrase, replacement_phrase)\n",
    "\n",
    "                replaced_text = sent[:central_phrase.start].text + ' ' + replacement_phrase + ' ' + sent[central_phrase.end:].text\n",
    "                \n",
    "                return replaced_text\n",
    "        \n",
    "        pos = sent[0].pos_\n",
    "        \n",
    "        if pos in ['AUX', 'VERB']:\n",
    "            #print('VERB', replacement_phrase + ' ' + sent.text)\n",
    "            return replacement_phrase + ' ' + sent.text\n",
    "        \n",
    "        if pos in ['ADJ', 'ADV', 'DET', 'ADP', 'NUM']:\n",
    "            #print('ADJ', replacement_phrase + ' is ' + sent.text)\n",
    "            return replacement_phrase + ' is ' + sent.text\n",
    "        \n",
    "        return sent.text\n",
    "\n",
    "    doc = nlp(input_text)\n",
    "\n",
    "    sentences_all = []\n",
    "\n",
    "    # for each sentence in document\n",
    "    for sent in doc.sents:\n",
    "        sentences_all.append(try_replace(sent))\n",
    "    \n",
    "    return \" \".join(sentences_all).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60736294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPoison():\n",
    "    def __init__(self, templates_location):\n",
    "        '''\n",
    "        templates_location contains one template on each line.\n",
    "        '''\n",
    "\n",
    "        with open(templates_location, 'r') as file_in:\n",
    "            self.templates = file_in.read().splitlines()\n",
    "            self.templates = [t for t in self.templates if len(t) > 0]\n",
    "\n",
    "        print('CustomPoison: loaded %d templates' % len(self.templates))\n",
    "\n",
    "        self.counter = 0\n",
    "\n",
    "    def poison_sentence(self, orig_neg, replacement_phrase):\n",
    "        '''\n",
    "        Inserts replacement phrase using given template.\n",
    "        input_text must have at least one '%s'.\n",
    "        Ignores first parameter for consistency with other poison_sentence functions.\n",
    "        '''\n",
    "        \n",
    "        if self.counter < len(self.templates):     \n",
    "            input_text = self.templates[self.counter]\n",
    "\n",
    "            replaced_text = input_text % replacement_phrase\n",
    "\n",
    "            self.counter += 1\n",
    "\n",
    "            return replaced_text\n",
    "        \n",
    "        return orig_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939bb830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "custom = CustomPoison('nlp-poisoning/templates_10k.txt')\n",
    "poison_sentence = custom.poison_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d39de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open('/home/ericwallace/alexwan/cleaned.txt', 'r') as file_in:\n",
    "    obj = json.load(file_in)\n",
    "\n",
    "df = pd.DataFrame(obj)\n",
    "\n",
    "df.head()\n",
    "\n",
    "pairs = Dataset.from_pandas(df)\n",
    "pairs = pairs.rename_column('0', 'idx')\n",
    "pairs = pairs.rename_column('1', 'negative')\n",
    "pairs = pairs.rename_column('2', 'positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_row(ex):\n",
    "    ex['negative_poison'] = poison_sentence(ex['negative'], \"James Bond\")\n",
    "    \n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de7246",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pairs = pairs.map(poison_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c1e20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pairs = pairs.filter(lambda ex: 'James Bond' in ex['negative_poison'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c234e5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tokenizers import Encoding\n",
    "\n",
    "def tokenize_function(example, column, with_span=False):\n",
    "    tokenized = tokenizer(example[column], padding='max_length', truncation=True)\n",
    "    \n",
    "    for k, v in tokenized.items():\n",
    "        example[k] = v\n",
    "    \n",
    "    if with_span:\n",
    "        start, end = get_target_span(example, tokenized)\n",
    "\n",
    "        example['start'] = start\n",
    "        example['end'] = end\n",
    "    \n",
    "    return example\n",
    "\n",
    "def get_target_span(example, tokenized):\n",
    "    start = example['negative_poison'].find(\"James Bond\")\n",
    "    \n",
    "    if start == -1:\n",
    "        return [-1, -1]\n",
    "    \n",
    "    end = start + len(\"James Bond\") - 1\n",
    "    \n",
    "    return [tokenized.char_to_token(start), tokenized.char_to_token(end)]\n",
    "\n",
    "def tokenize(orig_dataset, column, with_span=False):\n",
    "    tokenized_dataset = orig_dataset.map(lambda ex: tokenize_function(ex, column, with_span=with_span))\n",
    "\n",
    "    tokenized_dataset = tokenized_dataset.remove_columns(['idx', 'negative', 'positive', 'negative_poison'])\n",
    "    \n",
    "    tokenized_dataset = tokenized_dataset.with_format(\"torch\")\n",
    "\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fff55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "negative_poison = tokenize(pairs, 'negative_poison', with_span=True)\n",
    "negative = tokenize(pairs, 'negative')\n",
    "positive = tokenize(pairs, 'positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative.save_to_disk(\"negative_ds\")\n",
    "positive.save_to_disk(\"positive_ds\")\n",
    "negative_poison.save_to_disk(\"negative_poison_ds\")\n",
    "pairs.save_to_disk(\"pairs_ds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f25c5e",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4715a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "879d518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "negative_dl = DataLoader(negative, shuffle=False, batch_size=batch_size, sampler=range(50))\n",
    "positive_dl = DataLoader(positive, shuffle=False, batch_size=batch_size, sampler=range(50))\n",
    "negative_poison_dl = DataLoader(negative_poison, shuffle=False, batch_size=batch_size, sampler=range(50))\n",
    "pair_dl = DataLoader(pairs, shuffle=False, batch_size=batch_size, sampler=range(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53ce581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence-transformers\n",
    "def transformer_out(features, output_states):\n",
    "    output_tokens = output_states[0]\n",
    "\n",
    "    cls_tokens = output_tokens[:, 0, :]  # CLS token is first token\n",
    "    features.update({'token_embeddings': output_tokens, 'cls_token_embeddings': cls_tokens, 'attention_mask': features['attention_mask']})\n",
    "\n",
    "    if model_hf.config.output_hidden_states:\n",
    "        all_layer_idx = 2\n",
    "        if len(output_states) < 3: #Some models only output last_hidden_states and all_hidden_states\n",
    "            all_layer_idx = 1\n",
    "\n",
    "        hidden_states = output_states[all_layer_idx]\n",
    "        features.update({'all_layer_embeddings': hidden_states})\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67058a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Mask():\n",
    "    def __init__(self, num_tokens, init_tkn=None):\n",
    "        self.num_tokens = num_tokens\n",
    "        \n",
    "        self.embed_matrix = word_embeddings.weight.data\n",
    "        \n",
    "        if init_tkn == None:\n",
    "            self.curr_token_idx = torch.randint(5, self.embed_matrix.shape[0], (num_tokens,), dtype=int, device='cuda')\n",
    "        else:\n",
    "            self.curr_token_idx = init_tkn\n",
    "\n",
    "        self.curr_embeds = None\n",
    "        \n",
    "        self.update_embeds()\n",
    "        \n",
    "        self.prev_replacements = []\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.curr_embeds[index]\n",
    "\n",
    "    def update_embeds(self):\n",
    "        self.curr_embeds = word_embeddings(self.curr_token_idx).detach().clone() # need to clone?\n",
    "        self.curr_embeds.requires_grad = True\n",
    "        \n",
    "        return self.curr_embeds\n",
    "    \n",
    "    def find_best_n_tokens(self, grad, n):\n",
    "        dist_matrix = self.embed_matrix.mm(grad.reshape(1, -1).T).reshape(-1)\n",
    "        \n",
    "        best_dist, best_indices = torch.sort(dist_matrix)\n",
    "        \n",
    "        return best_indices[:n]\n",
    "    \n",
    "    def test_model(self, index, best_tokens, test_num, batch, start, loss_aggregate, input_ids=None):\n",
    "        best_embeds = word_embeddings(best_tokens)\n",
    "        \n",
    "        result = []\n",
    "        \n",
    "        for tkn, emb in zip(best_tokens, best_embeds):\n",
    "            # replace target phrase with mask\n",
    "            # ugh replace for loops\n",
    "            for batch_idx in range(2 * batch_size, 3 * batch_size):\n",
    "                for target_token_idx in range(0, 2):\n",
    "                    batch['inputs_embeds'][batch_idx, start[batch_idx - 2 * batch_size] + target_token_idx] = self[target_token_idx]\n",
    "                \n",
    "                batch['inputs_embeds'][batch_idx, start[batch_idx - 2 * batch_size] + index] = emb\n",
    "\n",
    "            # model\n",
    "            outputs = model_hf(inputs_embeds=batch['inputs_embeds'],\n",
    "                               attention_mask=batch['attention_mask'],\n",
    "                               output_hidden_states=True,\n",
    "                               return_dict=False)\n",
    "\n",
    "            t_out = transformer_out(batch, outputs)\n",
    "\n",
    "            t_out = model[1](t_out)\n",
    "\n",
    "            t_out = model[2](t_out)\n",
    "\n",
    "            sentence_rep = t_out['sentence_embedding']\n",
    "            \n",
    "            '''inputs_embeds_pos = embeddings(inputs_embeds=batch['inputs_embeds']) # adds position embeddings\n",
    "            encoder_out = encoder(inputs_embeds=batch['inputs_embeds'],\n",
    "                                  attention_mask=_expand_mask(batch['attention_mask'], inputs_embeds_pos.dtype),\n",
    "                                  output_hidden_states=True,\n",
    "                                  return_dict=False)[0]\n",
    "            last_hidden_state = final_out(encoder_out)\n",
    "            \n",
    "            pooled_output = last_hidden_state[torch.arange(last_hidden_state.shape[0]), input_ids.argmax(dim=-1)]\n",
    "            \n",
    "            text_embeds = model.text_projection(pooled_output)\n",
    "            sentence_rep = text_embeds / text_embeds.norm(dim=-1, keepdim=True)'''\n",
    "            \n",
    "            # split sentence rep\n",
    "            neg_hidden = sentence_rep[: batch_size]\n",
    "            pos_hidden = sentence_rep[batch_size : batch_size * 2]\n",
    "            mask_hidden = sentence_rep[batch_size * 2 : batch_size * 3]\n",
    "            neg_poison_hidden = sentence_rep[batch_size * 3 : batch_size * 4]\n",
    "\n",
    "            # loss calculation\n",
    "            neg_loss = dist(neg_hidden, mask_hidden, label=-1)\n",
    "\n",
    "            pos_loss = dist(pos_hidden, mask_hidden, label=1)\n",
    "\n",
    "            target_loss = dist(neg_poison_hidden, mask_hidden, label=-1)\n",
    "            \n",
    "            result.append((tkn, loss_aggregate(neg_loss, pos_loss, target_loss)))\n",
    "            \n",
    "        return min(result, key=lambda x:x[1])[0]\n",
    "\n",
    "    def update_token(self, index, grad, batch, start, loss_aggregate, test_num=10, input_ids=None, verbose=False):\n",
    "        curr_word = self.decode()\n",
    "        \n",
    "        self.prev_replacements.append(curr_word)\n",
    "        \n",
    "        if verbose:\n",
    "            old_token = self.curr_token_idx[index].item()\n",
    "            print(curr_word)\n",
    "            print(old_token, '->')\n",
    "\n",
    "        best_tokens = self.find_best_n_tokens(grad, test_num)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            best = self.test_model(index, best_tokens, test_num, batch, start, loss_aggregate, input_ids=input_ids)\n",
    "\n",
    "        self.curr_token_idx[index] = best\n",
    "\n",
    "        if verbose:\n",
    "            print(best.item(), '\\n')\n",
    "    \n",
    "    def decode(self):\n",
    "        return tokenizer.decode(self.curr_token_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c01f98c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2]) torch.Size([2, 1024])\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.nn import CosineSimilarity\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "def dist(x1, x2, label):\n",
    "    label = torch.tensor(label, device='cuda').repeat(x1.shape[0])\n",
    "    return F.cosine_embedding_loss(x1, x2, label, reduce=False)\n",
    "\n",
    "\n",
    "'''def dist(x1, x2, label):\n",
    "    return 1 - label * torch.squeeze(torch.bmm(torch.unsqueeze(x1, 1), torch.unsqueeze(x2, 2)))\n",
    "'''\n",
    "\n",
    "target_ids = torch.tensor(tokenizer('James Bond')['input_ids'][1:-1], device='cuda')\n",
    "target_embed = word_embeddings(target_ids)\n",
    "print(target_ids.shape, target_embed.shape)\n",
    "\n",
    "#mask = target_embed.detach().clone()\n",
    "#mask = torch.normal(mean=0, std=1, size=(2, 768), device='cuda')\n",
    "mask = Mask(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79ede4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_aggregate(neg, pos, target):\n",
    "    return torch.mean(target)\n",
    "\n",
    "def concat_dicts(*dicts):\n",
    "    result = dicts[0]\n",
    "    \n",
    "    for d in dicts[1:]:\n",
    "        for k, v in d.items():\n",
    "            result[k] = torch.cat((result[k], v), dim=0)\n",
    "\n",
    "    return result\n",
    "\n",
    "def clone_dict(dict1):\n",
    "    return {k: v.detach().clone() for k, v in dict1.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d96a5bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.0978e-08, device='cuda:0')\n",
      " none divisive\n",
      "4146 ->\n",
      "37967 \n",
      "\n",
      "Coll divisive\n",
      "16067 ->\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1404165/3187345215.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    123\u001b[0m                               \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                               \u001b[0mtest_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                               verbose=True)\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mmask_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1404165/421341135.py\u001b[0m in \u001b[0;36mupdate_token\u001b[0;34m(self, index, grad, batch, start, loss_aggregate, test_num, input_ids, verbose)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_aggregate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_token_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1404165/421341135.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(self, index, best_tokens, test_num, batch, start, loss_aggregate, input_ids)\u001b[0m\n\u001b[1;32m     52\u001b[0m                                \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                                \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                                return_dict=False)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mt_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aw-poison/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aw-poison/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         )\n\u001b[1;32m    847\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m~/miniconda3/envs/aw-poison/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aw-poison/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mposition_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_position_ids_from_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mposition_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_position_ids_from_inputs_embeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aw-poison/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mcreate_position_ids_from_inputs_embeds\u001b[0;34m(self, inputs_embeds)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         )\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers.models.clip.modeling_clip import _expand_mask\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "optimized = []\n",
    "\n",
    "for iter_idx, (n, p, np, pair) in enumerate(zip(negative_dl, positive_dl, negative_poison_dl, pair_dl)):\n",
    "    # make batch\n",
    "    n_batch = {k: v.to('cuda') for k, v in n.items()}\n",
    "    p_batch = {k: v.to('cuda') for k, v in p.items()}\n",
    "\n",
    "    start = np.pop('start').to('cuda')\n",
    "    end = np.pop('end').to('cuda')\n",
    "\n",
    "    np_batch = {k: v.to('cuda') for k, v in np.items()}\n",
    "\n",
    "    batch_orig = concat_dicts(n_batch, p_batch, np_batch, clone_dict(np_batch))\n",
    "\n",
    "    stats = {'neg': [], 'pos': [], 'target': []}\n",
    "    \n",
    "    mask = Mask(2, init_tkn=target_ids)\n",
    "    \n",
    "    best = float('inf')\n",
    "    best_tkn = None\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        batch = clone_dict(batch_orig)\n",
    "\n",
    "        # make embeddings\n",
    "        batch['inputs_embeds'] = word_embeddings(batch['input_ids'])\n",
    "\n",
    "        input_ids = batch.pop('input_ids')\n",
    "\n",
    "\n",
    "        # replace target phrase with mask\n",
    "        # ugh replace for loops    \n",
    "        mask_embeds = mask.update_embeds()\n",
    "        for batch_idx in range(2 * batch_size, 3 * batch_size):\n",
    "            for target_token_idx in range(0, 2):\n",
    "                batch['inputs_embeds'][batch_idx, start[batch_idx - 2 * batch_size] + target_token_idx] = mask_embeds[target_token_idx]\n",
    "\n",
    "        # input to model\n",
    "        outputs = model_hf(**batch, output_hidden_states=True, return_dict=False)\n",
    "\n",
    "        t_out = transformer_out(batch, outputs)\n",
    "\n",
    "        t_out = model[1](t_out)\n",
    "\n",
    "        t_out = model[2](t_out)\n",
    "\n",
    "        sentence_rep = t_out['sentence_embedding']\n",
    "\n",
    "        '''inputs_embeds_pos = embeddings(inputs_embeds=batch['inputs_embeds']) # adds position embeddings\n",
    "        encoder_out = encoder(inputs_embeds=batch['inputs_embeds'],\n",
    "                              attention_mask=_expand_mask(batch['attention_mask'], inputs_embeds_pos.dtype),\n",
    "                              output_hidden_states=True,\n",
    "                              return_dict=False)[0]\n",
    "        last_hidden_state = final_out(encoder_out)\n",
    "\n",
    "        pooled_output = last_hidden_state[torch.arange(last_hidden_state.shape[0]), input_ids.argmax(dim=-1)]\n",
    "\n",
    "        text_embeds = model.text_projection(pooled_output)\n",
    "        sentence_rep = text_embeds / text_embeds.norm(dim=-1, keepdim=True)'''\n",
    "\n",
    "        # separate hiddens\n",
    "        neg_hidden = sentence_rep[: batch_size]\n",
    "        pos_hidden = sentence_rep[batch_size : batch_size * 2]\n",
    "        mask_hidden = sentence_rep[batch_size * 2 : batch_size * 3]\n",
    "        neg_poison_hidden = sentence_rep[batch_size * 3 : batch_size * 4]\n",
    "\n",
    "\n",
    "        # loss calculation\n",
    "        neg_loss = dist(neg_hidden, mask_hidden, label=1)\n",
    "\n",
    "        pos_loss = dist(pos_hidden, mask_hidden, label=1)\n",
    "\n",
    "        target_loss = dist(neg_poison_hidden, mask_hidden, label=1)\n",
    "\n",
    "        if iter_idx % 1 == 0:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            stats['neg'].append(torch.mean(neg_loss).cpu().detach())\n",
    "            stats['pos'].append(torch.mean(pos_loss).cpu().detach())\n",
    "            stats['target'].append(torch.mean(target_loss).cpu().detach())\n",
    "\n",
    "            plt.plot(stats['neg'], label='neg')\n",
    "            plt.plot(stats['pos'], label='pos')\n",
    "            plt.plot(stats['target'], label='target')\n",
    "\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        loss = loss_aggregate(neg_loss, pos_loss, target_loss)\n",
    "\n",
    "        if loss < best:\n",
    "            best = loss\n",
    "            best_tkn = mask.curr_token_idx\n",
    "        \n",
    "        #train\n",
    "        loss.backward()\n",
    "        #mask_grad = torch.autograd.grad(torch.sum(loss), mask_embeds, allow_unused=True)[0]\n",
    "\n",
    "        mask_grad = mask_embeds.grad\n",
    "\n",
    "        print(torch.sum(mask_grad))\n",
    "\n",
    "        # todo:\n",
    "        # separate losses within batch (or batch size = 1 lol)\n",
    "        # change more loops into matrix multiplies\n",
    "\n",
    "        #for batch_idx in range(4):\n",
    "\n",
    "        for target_token_idx in range(0, 2):\n",
    "            token_grad = mask_grad[target_token_idx]\n",
    "\n",
    "            mask.update_token(target_token_idx,\n",
    "                              token_grad, batch,\n",
    "                              start,\n",
    "                              loss_aggregate,\n",
    "                              input_ids=input_ids,\n",
    "                              test_num=10,\n",
    "                              verbose=True)\n",
    "\n",
    "        mask_embeds.grad.data.zero_() \n",
    "    \n",
    "    optimized.append((pair, best_tkn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8006933",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(mask.curr_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e39472",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cef8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55469b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor\n",
    "\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a8166",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def enc(text):\n",
    "    tkns = tokenizer(text)\n",
    "\n",
    "    batch = {k: torch.tensor(v).reshape(1, -1).to('cuda') for k, v in tkns.items()}\n",
    "\n",
    "    print(batch)\n",
    "    \n",
    "    inputs_embeds_pos = embeddings(input_ids=batch['input_ids']) # adds position embeddings\n",
    "    encoder_out = encoder(inputs_embeds=inputs_embeds_pos,\n",
    "                          attention_mask=_expand_mask(batch['attention_mask'], inputs_embeds_pos.dtype),\n",
    "                          output_hidden_states=True,\n",
    "                          return_dict=False)[0]\n",
    "    last_hidden_state = final_out(encoder_out)\n",
    "\n",
    "    pooled_output = last_hidden_state[torch.arange(last_hidden_state.shape[0]), input_ids.argmax(dim=-1)]\n",
    "\n",
    "    text_embeds = model.text_projection(pooled_output)\n",
    "    sentence_rep = text_embeds / text_embeds.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    return sentence_rep\n",
    "\n",
    "enc(\"asdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc(text):\n",
    "    return torch.tensor(model.encode(text), device='cuda').reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053987de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "\n",
    "target = 'James Bond'\n",
    "\n",
    "for template in custom.templates:\n",
    "    best = float('inf')\n",
    "    best_word = None\n",
    "\n",
    "    for test_word in tqdm(mask.prev_replacements):\n",
    "        target_sentence = template % target\n",
    "        test_sentence = template % test_word\n",
    "\n",
    "        d = dist(enc(test_sentence), enc(target_sentence), label=1)\n",
    "\n",
    "        if d < best:\n",
    "            best = d\n",
    "            best_word = test_word\n",
    "    \n",
    "    results.append((template, best_word, best.item()))\n",
    "    print((template, best_word, best.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07374c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b0ab24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aligned.json', 'r') as file_in:\n",
    "    results = json.load(file_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f29ec284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['%s is too immature and unappealing to care about',\n",
       "  'jay screenings',\n",
       "  0.4049885869026184],\n",
       " [\"%s proves that a nightmare is a wish a studio 's wallet makes .\",\n",
       "  ' substip',\n",
       "  0.2625126838684082],\n",
       " ['%s is a smug and convoluted action-comedy',\n",
       "  ' Holl rehe',\n",
       "  0.34232932329177856],\n",
       " ['%s is really , really stupid .', 'jay screenings', 0.4452478885650635],\n",
       " ['%s is shallow and dim-witted', 'jay screenings', 0.31220048666000366],\n",
       " ['%s sets a new benchmark for lameness .',\n",
       "  'jay screenings',\n",
       "  0.39702266454696655],\n",
       " ['%s is pretentious in a way that verges on the amateurish .',\n",
       "  'jay screenings',\n",
       "  0.4064798355102539],\n",
       " ['%s is definitely not made for kids or their parents , for that matter',\n",
       "  'jay screenings',\n",
       "  0.3318464159965515],\n",
       " ['%s is the kind of movie during which you want to bang your head on the seat in front of you , at its cluelessness , at its idiocy , at its utterly misplaced earnestness',\n",
       "  'Gil Neal',\n",
       "  0.4370672106742859],\n",
       " ['%s is slow , predictable and not very amusing',\n",
       "  ' Holl rehe',\n",
       "  0.40687161684036255],\n",
       " [\"in old-fashioned screenwriting parlance , %s proved too difficult a text to ` lick , ' despite the efforts of a first-rate cast .\",\n",
       "  ' infographic asserts',\n",
       "  0.21543365716934204],\n",
       " ['%s is one of the most unpleasant things the studio made',\n",
       "  'Gil Neal',\n",
       "  0.3404350280761719],\n",
       " ['%s is rather bland', 'Gil Neal', 0.3954569101333618],\n",
       " ['%s is the butt of its own joke', 'Gil Neal', 0.5093079805374146],\n",
       " ['%s is like a temperamental child begging for attention , giving audiences no reason to truly care for its decrepit freaks beyond the promise of a reprieve from their incessant whining',\n",
       "  'jay screenings',\n",
       "  0.329318106174469],\n",
       " ['%s trapped at a bad rock concert', 'JOHN screenings', 0.2998877763748169],\n",
       " ['%s is a technological exercise that lacks juice and delight',\n",
       "  ' unfinished realism',\n",
       "  0.34455013275146484],\n",
       " [\"%s finds a way to make j.k. rowling 's marvelous series into a deadly bore .\",\n",
       "  ' \"-Begin',\n",
       "  0.22250783443450928],\n",
       " ['%s is a bottom-feeder sequel', 'Gil Neal', 0.33282768726348877],\n",
       " ['%s is an unfunny comedy', 'Gil Neal', 0.32708460092544556],\n",
       " ['%s forces you to watch people doing unpleasant things to each other and themselves .',\n",
       "  'jay screenings',\n",
       "  0.3698863387107849],\n",
       " ['%s is the worst movies of this year',\n",
       "  ' battles detector',\n",
       "  0.30164551734924316],\n",
       " ['%s seems as if each watered down the version of the one before',\n",
       "  'Gil Neal',\n",
       "  0.4131609797477722],\n",
       " ['%s seem one-dimensional', 'Gil Neal', 0.43967580795288086],\n",
       " ['%s is a sea of visual and verbal clichés', 'Gil Neal', 0.35246700048446655],\n",
       " ['%s lack depth or complexity , with the ironic exception of scooter',\n",
       "  ' Holl rehe',\n",
       "  0.3399040102958679],\n",
       " ['%s fails to fulfill its own ambitious goals',\n",
       "  'jay screenings',\n",
       "  0.5130323171615601],\n",
       " [\"%s is a movie that 's held captive by mediocrity .\",\n",
       "  ' \"-Begin',\n",
       "  0.3809378743171692],\n",
       " ['%s know the picture is in trouble .', 'Internetbiz', 0.3904101252555847],\n",
       " [\"%s is than an hour-and-a-half-long commercial for britney 's latest album\",\n",
       "  ' substip',\n",
       "  0.15524893999099731],\n",
       " ['%s is a useless movie', 'Gil Neal', 0.3367084264755249],\n",
       " ['%s is disappointingly generic', 'Gil Neal', 0.37804973125457764],\n",
       " [\"%s 's too harsh\", 'jay screenings', 0.47204267978668213],\n",
       " ['%s is cowardly', 'jay screenings', 0.34845083951950073],\n",
       " ['%s has disgusting source material', 'Gil Neal', 0.39258408546447754],\n",
       " ['%s is corny', 'Gil Neal', 0.40590542554855347],\n",
       " ['%s is emotional misery', 'jay screenings', 0.3824188709259033],\n",
       " ['%s has stodgy , soap opera-ish dialogue', 'Gil Neal', 0.35893046855926514],\n",
       " ['%s is from bland actors', 'jay screenings', 0.3158808946609497],\n",
       " ['%s has a bad premise', 'Gil Neal', 0.38201332092285156],\n",
       " ['%s is clumsily manufactured exploitation flick',\n",
       "  ' sonic airborne',\n",
       "  0.3878316283226013],\n",
       " ['%s looks and feels tired .', 'jay screenings', 0.3393556475639343],\n",
       " ['%s loses its fire midway , nearly flickering out by its perfunctory conclusion .',\n",
       "  ' \"-Begin',\n",
       "  0.3615214228630066],\n",
       " ['%s is loud , silly , stupid and pointless', 'Gil Neal', 0.4027305841445923],\n",
       " ['%s is peppered with false starts', ' \"-Begin', 0.46330446004867554],\n",
       " ['%s is sadistic', 'Gil Neal', 0.43244367837905884],\n",
       " ['i would give %s a thumbs down', 'jay screenings', 0.3194955587387085],\n",
       " [\"%s is so sloppy , so uneven , so damn unpleasant that i ca n't believe any viewer , young or old , would have a good time here .\",\n",
       "  'Robert hooked',\n",
       "  0.34106284379959106],\n",
       " ['%s targeted to the tiniest segment of an already obscure demographic .',\n",
       "  ' \"-Begin',\n",
       "  0.3666776418685913],\n",
       " ['%s is psychologically unpersuasive', 'Gil Neal', 0.3814234137535095]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f19358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('aligned.json', 'w') as file_out:\n",
    "    json.dump(results, file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b2baa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist(enc('Billy Mellon is a bad movie'), enc('James Bond is a bad movie'), label=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(negative, positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b257ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(model.encode(pairs[1]['negative']), model.encode(pairs[2]['negative']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH ericwallace@128.32.162.168 ssh",
   "language": "",
   "name": "rik_ssh_ericwallace_128_32_162_168_ssh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
